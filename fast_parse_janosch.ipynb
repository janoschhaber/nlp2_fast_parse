{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from formal import *\n",
    "from alg import * \n",
    "from earley import *\n",
    "from time import time\n",
    "import libitg\n",
    "import numpy as np\n",
    "import sys\n",
    "import dill as pickle\n",
    "\n",
    "from utils import read_lexicon, read_corpus, reduce_corpus, unk\n",
    "from features import simple_features\n",
    "\n",
    "\n",
    "def test(lexicon, src_str, tgt_str, verbose=False):\n",
    "    # if verbose: print(\"{} - {}\".format(src_str, tgt_str))\n",
    "        \n",
    "    # Make a source CFG using the whole lexicon\n",
    "    src_cfg = libitg.make_source_side_finite_itg(lexicon)\n",
    "\n",
    "    # Make a source FSA\n",
    "    src_fsa = libitg.make_fsa(src_str)\n",
    "\n",
    "    # Make a target FSA\n",
    "    tgt_fsa = libitg.make_fsa(tgt_str)\n",
    "\n",
    "    # Intersect source FSA and source CFG\n",
    "    _Dx = libitg.earley(src_cfg, src_fsa, \n",
    "            start_symbol=Nonterminal('S'), \n",
    "            sprime_symbol=Nonterminal(\"D(x)\"),\n",
    "            clean=True)  # to illustrate the difference between clean and dirty forests I will disable clean here\n",
    "\n",
    "    # projection over target vocabulary - D(x) is now finite\n",
    "    Dx_clean = libitg.make_target_side_finite_itg(_Dx, lexicon)\n",
    "    \n",
    "    Dxy_clean = libitg.earley(Dx_clean, tgt_fsa,\n",
    "            start_symbol=Nonterminal(\"D(x)\"), \n",
    "            sprime_symbol=Nonterminal('D(x,y)'),\n",
    "            clean=True)\n",
    "    \n",
    "    # pickle the data\n",
    "    if len(Dxy_clean) > 0:       \n",
    "        # print('D(x) (cleaned): %d rules in %.4f secs' % (len(Dx_clean), times['D(x)']))\n",
    "        # print('D(x,y) (cleaned): %d rules in %.4f secs ' % (len(Dxy_clean), times['D(x,y)']))\n",
    "        # if verbose: print('D(x): %d rules, D(x,y): %d rules \\n' % (len(Dx_clean), len(Dxy_clean)))\n",
    "        # with open('pickle-test', 'wb') as f:\n",
    "        #     pickle.dump(Dxy_clean, f)\n",
    "        # TODO: Save to file\n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        # if verbose: print ('Empty D(x,y) \\n')\n",
    "        return False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEXICON (excerpt)\n",
      "能: {'able', 'will', 'me', 'could', '-', 'would', 'get', 'may', 'possible', 'can'}\n",
      "折: {'discounted', 'marked', 'wouldn', '-', 'percent', 'impossible', 'cut-price', 'lowered', 'reduced', 'gimme'}\n",
      "我: {'me', 'i', '-', \"'d\", '.', \"'m\", 'to', 'like', 'a', 'my'}\n",
      "段: {'short', 'longer', 'lately', '-', 'while', 'things', 'tricks', 'been', 'period', 'park'}\n",
      "或者: {'articles', 'hmmm', 'bump', 'mmm-hmm', '-', 'contacts', 'ahold', 'liquors', 'or', 'lenny'}\n",
      "椭圆: {'-', 'standing', 'an', 'oval', 'one', 'counter', 'be', 'next', 'right', 'rent-a-car'}\n",
      "明早: {'o', 'a.m.', '-', 'morning', 'eight', 'wake-up', 'tomorrow', 'wake', \"'clock\", 'sets'}\n",
      "大约: {'-', 'ten-minute', 'about', 'approximately', 'national', 'takes', 'holidays', 'around', 'or', 'so'}\n",
      "一一一四: {'will', 'yoshida', '-', 'of', 'eleven', 'hand', 'room', 'fourteen', 'ms.', 'note'}\n",
      "药片: {'-', 'tablet', 'indigestion', 'whole', 'cough', 'swallow', 'some', 'drops', 'tablets', 'must'}\n",
      "-EPS-: {'me', 'here', 'could', 'how', \"'d\", \"'ll\", 'does', 'what', 'do', 'with', \"'s\", 'a', 'got', 'my', 'your', 'will', 'i', 'you', 'the', '-UNK-', 'it', \"'m\", 'one', 'of', 'to', ',', 'is', 'want', 'please', 'would', '?', 'at', 'for', 'in', 'on', 'about', 'and', 'be', 'have', 'like', 'take', 'right', 'can', 'there', 'are', '.', 'this', 'go', 'we', 'get', 'that'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lexicon, prob = read_lexicon('data/lexicon', top=10)\n",
    "\n",
    "print('LEXICON (excerpt)')\n",
    "limit = 10\n",
    "counter = 0\n",
    "for src_word, tgt_words in lexicon.items():\n",
    "    print('%s: %s' % (src_word, tgt_words))\n",
    "    counter += 1\n",
    "    if counter == limit: break\n",
    "print('-EPS-: %s' %lexicon['-EPS-'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = read_corpus('data/training.zh-en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING INSTANCE 0: |x|=4 |y|=7\n",
      "TRAINING INSTANCE 1: |x|=8 |y|=7\n",
      "TRAINING INSTANCE 2: |x|=11 |y|=13\n",
      "TRAINING INSTANCE 3: |x|=4 |y|=5\n",
      "Parse successful\n",
      "TRAINING INSTANCE 4: |x|=13 |y|=12\n",
      "TRAINING INSTANCE 5: |x|=5 |y|=5\n",
      "TRAINING INSTANCE 6: |x|=7 |y|=5\n",
      "TRAINING INSTANCE 7: |x|=8 |y|=10\n",
      "TRAINING INSTANCE 8: |x|=10 |y|=13\n",
      "Parse successful\n",
      "TRAINING INSTANCE 9: |x|=7 |y|=6\n",
      "\n",
      "10 parsed in 28.9333 secs - 2 additional parses\n",
      "\n",
      "TRAINING INSTANCE 10: |x|=20 |y|=13\n",
      "TRAINING INSTANCE 11: |x|=4 |y|=4\n",
      "Parse successful\n",
      "TRAINING INSTANCE 12: |x|=6 |y|=6\n",
      "TRAINING INSTANCE 13: |x|=8 |y|=7\n",
      "TRAINING INSTANCE 14: |x|=13 |y|=10\n",
      "TRAINING INSTANCE 15: |x|=5 |y|=7\n",
      "TRAINING INSTANCE 16: |x|=9 |y|=8\n",
      "TRAINING INSTANCE 17: |x|=9 |y|=9\n",
      "TRAINING INSTANCE 18: |x|=2 |y|=3\n",
      "Parse successful\n",
      "TRAINING INSTANCE 19: |x|=13 |y|=14\n",
      "\n",
      "20 parsed in 32.8524 secs - 2 additional parses\n",
      "\n",
      "TRAINING INSTANCE 20: |x|=6 |y|=7\n",
      "Parse successful\n",
      "Total of 5 pairs parsed\n"
     ]
    }
   ],
   "source": [
    "limit = 20\n",
    "parse_count = 0\n",
    "last_count = 0\n",
    "\n",
    "times = dict()\n",
    "times[10] = time()\n",
    "for i, (s_zh, s_en) in enumerate(corpus):    \n",
    "    if i > 0 and i % 10 == 0: \n",
    "        times[i] = time() - times[i]\n",
    "        print('\\n%i parsed in %.4f secs - %i additional parses\\n' % (i, times[i], parse_count - last_count))\n",
    "        times[i+10] = time()\n",
    "        last_count = parse_count\n",
    "       \n",
    "    \n",
    "    print('TRAINING INSTANCE %i: |x|=%d |y|=%d' % (i, len(s_zh.split()), len(s_en.split())))\n",
    "    parse = test(lexicon, \n",
    "            s_zh,\n",
    "            s_en,\n",
    "            verbose = False)\n",
    "    \n",
    "    if parse is True: \n",
    "        parse_count += 1\n",
    "        print(\"Parse successful\")\n",
    "    if i == limit: break\n",
    "        \n",
    "print('Total of %i pairs parsed' % (parse_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('pickle-test', 'rb') as f:\n",
    "    Dloaded = pickle.load(f)\n",
    "\n",
    "print(len(Dloaded), 'loaded')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D(x)]:0-7 ||| [S]:0-6:0-7\n",
      "[S]:0-6:0-7 ||| [X]:0-6:0-7\n",
      "[X]:0-6:0-7 ||| [X]:5-6:0-1 [X]:0-5:1-7\n",
      "[X]:0-6:0-7 ||| [X]:0-3:0-4 [X]:3-6:4-7\n",
      "[X]:0-6:0-7 ||| [X]:0-4:0-5 [X]:4-6:5-7\n",
      "[X]:0-6:0-7 ||| [X]:0-1:0-1 [X]:1-6:1-7\n",
      "[X]:0-6:0-7 ||| [X]:0-1:0-2 [X]:1-6:2-7\n",
      "[X]:0-6:0-7 ||| [X]:0-5:0-6 [X]:5-6:6-7\n",
      "[X]:0-6:0-7 ||| [X]:0-2:0-2 [X]:2-6:2-7\n",
      "[X]:0-6:0-7 ||| [X]:0-2:0-3 [X]:2-6:3-7\n",
      "[X]:0-6:0-7 ||| [X]:5-6:0-2 [X]:0-5:2-7\n",
      "[X]:0-6:0-7 ||| [X]:1-6:0-6 [X]:0-1:6-7\n",
      "[X]:5-6:0-1 ||| [T]:5-6:0-1\n",
      "[X]:5-6:0-2 ||| [T]:5-6:0-1 [I]:6-6:1-2\n",
      "[X]:5-6:0-2 ||| [T]:5-6:0-1 [I]:5-5:1-2\n",
      "[X]:0-5:1-7 ||| [X]:1-5:1-6 [X]:0-1:6-7\n",
      "[X]:0-3:0-4 ||| [X]:0-1:0-1 [X]:1-3:1-4\n",
      "[X]:0-3:0-4 ||| [X]:0-2:0-2 [X]:2-3:2-4\n",
      "[X]:0-3:0-4 ||| [X]:0-1:0-2 [X]:1-3:2-4\n",
      "[X]:0-3:0-4 ||| [X]:0-2:0-3 [X]:2-3:3-4\n",
      "[X]:3-6:4-7 ||| [X]:3-5:4-6 [X]:5-6:6-7\n",
      "[X]:3-6:4-7 ||| [X]:3-4:4-5 [X]:4-6:5-7\n",
      "[X]:0-4:0-5 ||| [X]:0-1:0-2 [X]:1-4:2-5\n",
      "[X]:0-4:0-5 ||| [X]:0-3:0-4 [X]:3-4:4-5\n",
      "[X]:0-4:0-5 ||| [X]:0-2:0-2 [X]:2-4:2-5\n",
      "[X]:0-4:0-5 ||| [X]:0-2:0-3 [X]:2-4:3-5\n",
      "[X]:0-4:0-5 ||| [X]:0-1:0-1 [X]:1-4:1-5\n",
      "[X]:4-6:5-7 ||| [X]:4-5:5-6 [X]:5-6:6-7\n",
      "[X]:0-1:0-2 ||| [T]:0-1:0-1 [I]:1-1:1-2\n",
      "[X]:0-1:0-2 ||| [T]:0-1:0-1 [I]:0-0:1-2\n",
      "[X]:0-1:0-1 ||| [T]:0-1:0-1\n",
      "[X]:1-6:1-7 ||| [X]:1-4:1-5 [X]:4-6:5-7\n",
      "[X]:1-6:1-7 ||| [X]:1-2:1-3 [X]:2-6:3-7\n",
      "[X]:1-6:1-7 ||| [X]:1-2:1-2 [X]:2-6:2-7\n",
      "[X]:1-6:1-7 ||| [X]:1-5:1-6 [X]:5-6:6-7\n",
      "[X]:1-6:1-7 ||| [X]:1-3:1-4 [X]:3-6:4-7\n",
      "[X]:1-6:2-7 ||| [X]:1-5:2-6 [X]:5-6:6-7\n",
      "[X]:1-6:2-7 ||| [X]:1-2:2-3 [X]:2-6:3-7\n",
      "[X]:1-6:2-7 ||| [X]:1-4:2-5 [X]:4-6:5-7\n",
      "[X]:1-6:2-7 ||| [X]:1-3:2-4 [X]:3-6:4-7\n",
      "[X]:0-5:0-6 ||| [X]:0-1:0-1 [X]:1-5:1-6\n",
      "[X]:0-5:0-6 ||| [X]:0-2:0-3 [X]:2-5:3-6\n",
      "[X]:0-5:0-6 ||| [X]:0-4:0-5 [X]:4-5:5-6\n",
      "[X]:0-5:0-6 ||| [X]:0-3:0-4 [X]:3-5:4-6\n",
      "[X]:0-5:0-6 ||| [X]:0-1:0-2 [X]:1-5:2-6\n",
      "[X]:0-5:0-6 ||| [X]:0-2:0-2 [X]:2-5:2-6\n",
      "[X]:5-6:6-7 ||| [T]:5-6:6-7\n",
      "[X]:0-2:0-3 ||| [X]:0-1:0-1 [X]:1-2:1-3\n",
      "[X]:0-2:0-3 ||| [X]:0-1:0-2 [X]:1-2:2-3\n",
      "[X]:0-2:0-2 ||| [X]:0-1:0-1 [X]:1-2:1-2\n",
      "[X]:2-6:2-7 ||| [X]:2-3:2-4 [X]:3-6:4-7\n",
      "[X]:2-6:2-7 ||| [X]:2-5:2-6 [X]:5-6:6-7\n",
      "[X]:2-6:2-7 ||| [X]:2-4:2-5 [X]:4-6:5-7\n",
      "[X]:2-6:3-7 ||| [X]:2-3:3-4 [X]:3-6:4-7\n",
      "[X]:2-6:3-7 ||| [X]:2-4:3-5 [X]:4-6:5-7\n",
      "[X]:2-6:3-7 ||| [X]:2-5:3-6 [X]:5-6:6-7\n",
      "[X]:0-5:2-7 ||| [X]:1-5:2-6 [X]:0-1:6-7\n",
      "[X]:1-6:0-6 ||| [X]:5-6:0-1 [X]:1-5:1-6\n",
      "[X]:1-6:0-6 ||| [X]:5-6:0-2 [X]:1-5:2-6\n",
      "[X]:0-1:6-7 ||| [T]:0-1:6-7\n",
      "[T]:5-6:0-1 ||| 'i':5-6:0-1\n",
      "[I]:6-6:1-2 ||| ''ll':6-6:1-2\n",
      "[I]:5-5:1-2 ||| ''ll':5-5:1-2\n",
      "[X]:1-5:1-6 ||| [X]:1-2:1-2 [X]:2-5:2-6\n",
      "[X]:1-5:1-6 ||| [X]:1-3:1-4 [X]:3-5:4-6\n",
      "[X]:1-5:1-6 ||| [X]:1-2:1-3 [X]:2-5:3-6\n",
      "[X]:1-5:1-6 ||| [X]:1-4:1-5 [X]:4-5:5-6\n",
      "[X]:1-3:1-4 ||| [X]:1-2:1-3 [X]:2-3:3-4\n",
      "[X]:1-3:1-4 ||| [X]:1-2:1-2 [X]:2-3:2-4\n",
      "[X]:2-3:2-4 ||| [I]:3-3:2-3 [T]:2-3:3-4\n",
      "[X]:2-3:2-4 ||| [I]:2-2:2-3 [T]:2-3:3-4\n",
      "[X]:1-3:2-4 ||| [X]:1-2:2-3 [X]:2-3:3-4\n",
      "[X]:2-3:3-4 ||| [T]:2-3:3-4\n",
      "[X]:3-5:4-6 ||| [X]:3-4:4-5 [X]:4-5:5-6\n",
      "[X]:3-4:4-5 ||| [T]:3-4:4-5\n",
      "[X]:1-4:2-5 ||| [X]:1-3:2-4 [X]:3-4:4-5\n",
      "[X]:1-4:2-5 ||| [X]:1-2:2-3 [X]:2-4:3-5\n",
      "[X]:2-4:2-5 ||| [X]:2-3:2-4 [X]:3-4:4-5\n",
      "[X]:2-4:3-5 ||| [X]:2-3:3-4 [X]:3-4:4-5\n",
      "[X]:1-4:1-5 ||| [X]:1-3:1-4 [X]:3-4:4-5\n",
      "[X]:1-4:1-5 ||| [X]:1-2:1-2 [X]:2-4:2-5\n",
      "[X]:1-4:1-5 ||| [X]:1-2:1-3 [X]:2-4:3-5\n",
      "[X]:4-5:5-6 ||| [T]:4-5:5-6\n",
      "[T]:0-1:0-1 ||| 'i':0-1:0-1\n",
      "[I]:1-1:1-2 ||| ''ll':1-1:1-2\n",
      "[I]:0-0:1-2 ||| ''ll':0-0:1-2\n",
      "[X]:1-2:1-2 ||| [T]:1-2:1-2\n",
      "[X]:1-2:1-3 ||| [I]:2-2:1-2 [T]:1-2:2-3\n",
      "[X]:1-2:1-3 ||| [T]:1-2:1-2 [I]:1-1:2-3\n",
      "[X]:1-2:1-3 ||| [T]:1-2:1-2 [I]:2-2:2-3\n",
      "[X]:1-2:1-3 ||| [I]:1-1:1-2 [T]:1-2:2-3\n",
      "[X]:1-5:2-6 ||| [X]:1-2:2-3 [X]:2-5:3-6\n",
      "[X]:1-5:2-6 ||| [X]:1-3:2-4 [X]:3-5:4-6\n",
      "[X]:1-5:2-6 ||| [X]:1-4:2-5 [X]:4-5:5-6\n",
      "[X]:1-2:2-3 ||| [T]:1-2:2-3\n",
      "[X]:2-5:3-6 ||| [X]:2-4:3-5 [X]:4-5:5-6\n",
      "[X]:2-5:3-6 ||| [X]:2-3:3-4 [X]:3-5:4-6\n",
      "[X]:2-5:2-6 ||| [X]:2-4:2-5 [X]:4-5:5-6\n",
      "[X]:2-5:2-6 ||| [X]:2-3:2-4 [X]:3-5:4-6\n",
      "[T]:5-6:6-7 ||| '.':5-6:6-7\n",
      "[T]:0-1:6-7 ||| '.':0-1:6-7\n",
      "[I]:3-3:2-3 ||| 'be':3-3:2-3\n",
      "[T]:2-3:3-4 ||| 'staying':2-3:3-4\n",
      "[I]:2-2:2-3 ||| 'be':2-2:2-3\n",
      "[T]:3-4:4-5 ||| 'two':3-4:4-5\n",
      "[T]:4-5:5-6 ||| 'days':4-5:5-6\n",
      "[T]:1-2:1-2 ||| ''ll':1-2:1-2\n",
      "[I]:2-2:1-2 ||| ''ll':2-2:1-2\n",
      "[T]:1-2:2-3 ||| 'be':1-2:2-3\n",
      "[I]:1-1:2-3 ||| 'be':1-1:2-3\n",
      "[D(x,y)] ||| [D(x)]:0-7\n"
     ]
    }
   ],
   "source": [
    "for d in Dloaded:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
